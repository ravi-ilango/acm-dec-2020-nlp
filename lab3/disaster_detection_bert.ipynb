{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6w6mhl0GOjk"
   },
   "source": [
    "## Disaster or not: Text Classification using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FLs8SMhVGOjl",
    "outputId": "693a8806-9e0c-4458-d872-8e0f2e9afb71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-16 06:05:24--  https://github.com/ravi-ilango/acm-dec-2020-nlp/blob/main/lab3/disaster_data.zip?raw=true\n",
      "Resolving github.com (github.com)... 13.114.40.48\n",
      "Connecting to github.com (github.com)|13.114.40.48|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://github.com/ravi-ilango/aicamp-mar-2021/blob/main/lab3/disaster_data.zip?raw=true [following]\n",
      "--2021-03-16 06:05:25--  https://github.com/ravi-ilango/aicamp-mar-2021/blob/main/lab3/disaster_data.zip?raw=true\n",
      "Reusing existing connection to github.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github.com/ravi-ilango/aicamp-mar-2021/raw/main/lab3/disaster_data.zip [following]\n",
      "--2021-03-16 06:05:25--  https://github.com/ravi-ilango/aicamp-mar-2021/raw/main/lab3/disaster_data.zip\n",
      "Reusing existing connection to github.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/ravi-ilango/aicamp-mar-2021/main/lab3/disaster_data.zip [following]\n",
      "--2021-03-16 06:05:25--  https://raw.githubusercontent.com/ravi-ilango/aicamp-mar-2021/main/lab3/disaster_data.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 409718 (400K) [application/zip]\n",
      "Saving to: ‘disaster_data.zip’\n",
      "\n",
      "disaster_data.zip   100%[===================>] 400.12K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2021-03-16 06:05:26 (9.54 MB/s) - ‘disaster_data.zip’ saved [409718/409718]\n",
      "\n",
      "Archive:  disaster_data.zip\n",
      "   creating: disaster_data/\n",
      "  inflating: disaster_data/train.csv  \n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/ravi-ilango/acm-dec-2020-nlp/blob/main/lab3/disaster_data.zip?raw=true -O disaster_data.zip\n",
    "\n",
    "!unzip disaster_data.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6J4BJ_ZpJ9tx",
    "outputId": "8b3c6065-978f-4de0-93dd-8c0f8c98ca78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.3.3)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DkU5XHhZSaYT"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig, AdamW\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pexPsED6GOjt"
   },
   "outputs": [],
   "source": [
    "model_path = './bert_disaster_detection_state_dict.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce5ZsT6bGOjw"
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QX8SHDxIanDm",
    "outputId": "0a504bec-7ade-4ca9-e883-0772c9e26094"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613,)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# queries are stored in the variable query_text\n",
    "# correct intent labels are stored in the variable labels\n",
    "#\n",
    "query_text = pd.read_csv('./disaster_data/train.csv').text.values\n",
    "labels = pd.read_csv('./disaster_data/train.csv').target.values\n",
    "\n",
    "print(query_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "QGBCR4tyTpff",
    "outputId": "de27f524-684a-424e-fa9e-4013582db809"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(labels)\n",
    "plt.xlabel('target')\n",
    "plt.ylabel('count')\n",
    "plt.title('target distribution')\n",
    "plt.xticks(np.arange(len(np.unique(labels))));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yIdLCbrkGOj8"
   },
   "source": [
    "### Prepare Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e1ik34PToVtp",
    "outputId": "5befd903-ac5e-4f4b-a2f5-ac2ab7ed663f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized inputs [101, 2256, 15616, 2024, 1996, 3114, 1997, 2023, 1001, 8372, 2089, 16455, 9641, 2149, 2035, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize with BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "padded_sequences = tokenizer(list(query_text), padding=True)\n",
    "print (f\"tokenized inputs {padded_sequences['input_ids'][0]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qeDT5ynroVtp",
    "outputId": "93b3b28c-d6c9-4cc0-8404-8b069597bd43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ARoMIuySoVtp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptLywUVhXxAg"
   },
   "source": [
    "### Split into train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FPrG98fJXWrh"
   },
   "outputs": [],
   "source": [
    "# Use train_test_split to split our data into train and validation sets for training\n",
    "input_ids = padded_sequences['input_ids']\n",
    "attention_masks = padded_sequences['attention_mask']\n",
    "\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=2018, test_size=0.1)\n",
    "\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                             random_state=2018, test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tcvM3OuyoVtq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCzTABSaGOkC"
   },
   "source": [
    "### Convert data into torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TvWkX6CTGOkC"
   },
   "outputs": [],
   "source": [
    "# Convert data into torch tensors\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7rhRXCrgoVtq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sj3swD8IGOkF"
   },
   "source": [
    "### Create a data generator (iterator) for the train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Uq3uMXwnGOkF"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# Create an iterator of train data with torch DataLoader \n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create an iterator of validation data with torch DataLoader \n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxDd2eiQX0Q_"
   },
   "source": [
    "### Load pretrained BERT model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVZIZUN0UTL4",
    "outputId": "46355138-0dd4-4421-da3a-c576569ba35c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "# specify GPU device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print (torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FxVF3J24XZYV",
    "outputId": "d9f0694b-548f-40b7-b35e-05cff89785ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. \n",
    "\n",
    "num_labels = 2\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", \n",
    "                                                      num_labels=num_labels)\n",
    "model.to(device)\n",
    "\n",
    "# BERT fine-tuning parameters\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                     lr=2e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yeqZoDIyGOkN",
    "outputId": "a6ef7e34-255a-4b38-f52d-4782f32784a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from saved model...\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(model_path):\n",
    "    print (\"Loading weights from saved model...\")\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "H_WSsKElXidy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxc-v5RWGOkQ"
   },
   "source": [
    "### Model Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_rqqU_V-GOkQ"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer):\n",
    "\n",
    "    model.train()  \n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for step, batch in enumerate(iterator):\n",
    "        \n",
    "        #retrieve input data\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        #resets the gradients after every batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss = output['loss']\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters and take a step using the computed gradient\n",
    "        optimizer.step()\n",
    "        \n",
    "        # loss\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        if step%50==0:\n",
    "            print (f\"step: {step}\")\n",
    "\n",
    "    \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rybJV8uRGOkT"
   },
   "source": [
    "### Model Evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "4Bcl2EmiGOkT"
   },
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "# Evaluate\n",
    "def evaluate(model, iterator):\n",
    "    \n",
    "    #initialize every epoch\n",
    "    epoch_acc = 0\n",
    "\n",
    "    #deactivating dropout layers\n",
    "    model.eval()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        #retrieve input data\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        #deactivates autograd\n",
    "        with torch.no_grad():\n",
    "            # Forward pass, calculate logit predictions\n",
    "            output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "            logits = output['logits']\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)    \n",
    "        epoch_acc += tmp_eval_accuracy\n",
    "        \n",
    "    return epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJ8MxrmPXrj_"
   },
   "source": [
    "### Train and Validate\n",
    "This step takes ~3min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9zxNbWGWGOkW",
    "outputId": "6289b063-708d-4d3b-de7a-046eb2d86d4d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0\n",
      "step: 50\n",
      "step: 100\n",
      "step: 150\n",
      "step: 200\n",
      "saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|███▎      | 1/3 [01:02<02:04, 62.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Train Loss: 0.340 | Val. Acc: 85.27%\n",
      "step: 0\n",
      "step: 50\n",
      "step: 100\n",
      "step: 150\n",
      "step: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████▋   | 2/3 [02:02<01:01, 61.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Train Loss: 0.266 | Val. Acc: 84.22%\n",
      "step: 0\n",
      "step: 50\n",
      "step: 100\n",
      "step: 150\n",
      "step: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 3/3 [03:03<00:00, 61.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Train Loss: 0.197 | Val. Acc: 83.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 3\n",
    "best_valid_acc = 0\n",
    "\n",
    "# BERT training loop\n",
    "for _ in trange(N_EPOCHS, desc=\"Epoch\"):  \n",
    "\n",
    "    #train the model\n",
    "    train_loss = train(model, train_dataloader, optimizer)\n",
    "    \n",
    "    #evaluate the model\n",
    "    valid_acc = evaluate(model, validation_dataloader)\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        print (\"saving model ...\")\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ga-WimCQGOkZ"
   },
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "UOoGLAHsGOkZ"
   },
   "outputs": [],
   "source": [
    "#load weights\n",
    "model.to('cpu')\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "def predict(model, sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    output = model(**inputs)\n",
    "    logits = output.logits\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "\n",
    "    pred = np.argmax(logits, axis=1)[0]\n",
    "    return 'Disaster' if pred == 1 else 'Not a disaster'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "t227g_VuGOkb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "138KWbajGOkf",
    "outputId": "6c1ee10e-363f-4b44-cf1d-7aafb518f649"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Disaster'"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, \"Forest fire near La Ronge Sask. Canada\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Wu2uBSz0GOki",
    "outputId": "a529eaba-738e-401c-b2d1-5288bead105e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Not a disaster'"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, \"The weather is awesome\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J2pnJ1xjGOkl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0vEpMVvuGOkn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "disaster_detection_bert.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
