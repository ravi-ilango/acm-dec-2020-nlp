{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "quora_classifier_lstm.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFHRl3Tj28T1"
      },
      "source": [
        "# Quora Insincere Questions Classification\n",
        "## Detect toxic content to improve online conversations\n",
        "\n",
        "### Note: Set the colab runtime to None (cpu) for this notebook to work\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6NiNjAo28T4",
        "outputId": "5605461d-1d48-46c3-8a8a-dc37f6499ffa"
      },
      "source": [
        "!wget https://github.com/ravi-ilango/acm-dec-2020-nlp/blob/main/lab2_1/quora_data.zip?raw=true -O quora_data.zip\n",
        "\n",
        "!unzip quora_data.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-12 09:59:51--  https://github.com/ravi-ilango/acm-dec-2020-nlp/blob/main/lab2_1/quora_data.zip?raw=true\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://github.com/ravi-ilango/aicamp-mar-2021/blob/main/lab2_1/quora_data.zip?raw=true [following]\n",
            "--2021-03-12 09:59:51--  https://github.com/ravi-ilango/aicamp-mar-2021/blob/main/lab2_1/quora_data.zip?raw=true\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/ravi-ilango/aicamp-mar-2021/raw/main/lab2_1/quora_data.zip [following]\n",
            "--2021-03-12 09:59:51--  https://github.com/ravi-ilango/aicamp-mar-2021/raw/main/lab2_1/quora_data.zip\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/ravi-ilango/aicamp-mar-2021/main/lab2_1/quora_data.zip [following]\n",
            "--2021-03-12 09:59:51--  https://raw.githubusercontent.com/ravi-ilango/aicamp-mar-2021/main/lab2_1/quora_data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 57048760 (54M) [application/zip]\n",
            "Saving to: ‘quora_data.zip’\n",
            "\n",
            "quora_data.zip      100%[===================>]  54.41M   296MB/s    in 0.2s    \n",
            "\n",
            "2021-03-12 09:59:52 (296 MB/s) - ‘quora_data.zip’ saved [57048760/57048760]\n",
            "\n",
            "Archive:  quora_data.zip\n",
            "   creating: quora_data/\n",
            "  inflating: quora_data/train.csv    \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/quora_data/\n",
            "  inflating: __MACOSX/quora_data/._train.csv  \n",
            "  inflating: __MACOSX/._quora_data   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "id": "1HjgPSTR6FAk",
        "outputId": "abd480d9-70dc-45f9-bfdf-fc5d2d5420ed"
      },
      "source": [
        "!pip install torch==1.6.0\n",
        "!pip install torchtext==0.7.0"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/5e/35140615fc1f925023f489e71086a9ecc188053d263d3594237281284d82/torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8MB)\n",
            "\u001b[K     |████████████████████████████████| 748.8MB 19kB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (1.19.5)\n",
            "\u001b[31mERROR: torchvision 0.9.0+cu101 has requirement torch==1.8.0, but you'll have torch 1.6.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.0 has requirement torch==1.8.0, but you'll have torch 1.6.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.8.0+cu101\n",
            "    Uninstalling torch-1.8.0+cu101:\n",
            "      Successfully uninstalled torch-1.8.0+cu101\n",
            "Successfully installed torch-1.6.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/6d/a6f757ab75c57868a7ae0e839d631f3384e7e992216bd8cb21739358b5b1/torchtext-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (4.5MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5MB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.7.0) (1.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.7.0) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.7.0) (4.41.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 36.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.7.0) (2.23.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.7.0) (0.16.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.7.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.7.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.7.0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.7.0) (1.24.3)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Found existing installation: torchtext 0.9.0\n",
            "    Uninstalling torchtext-0.9.0:\n",
            "      Successfully uninstalled torchtext-0.9.0\n",
            "Successfully installed sentencepiece-0.1.95 torchtext-0.7.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torchtext"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0NUpK6S28T5"
      },
      "source": [
        "import random\n",
        "\n",
        "import os\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "#deal with tensors\n",
        "import torch   \n",
        "\n",
        "#handling text data\n",
        "from torchtext import data \n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "#for attention LSTM\n",
        "from torch.autograd import Variable\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF1M-VNk28T6"
      },
      "source": [
        "#Reproducing same results\n",
        "SEED = 2315\n",
        "\n",
        "#Torch\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "#Cuda algorithms\n",
        "torch.backends.cudnn.deterministic = True "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svJCWEc928T7"
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t89iul9p28T7"
      },
      "source": [
        "### Load custom dataset using torchtext.data.TabularDataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLzkyD-N28T8",
        "outputId": "39f9c7e8-df1b-4542-c9cc-afc9cf1a417d"
      },
      "source": [
        "#loading custom dataset\n",
        "\n",
        "def tokenizer(text): # create a tokenizer function\n",
        "    return text.split(' ')\n",
        "\n",
        "TEXT = data.Field(tokenize=tokenizer,batch_first=True,include_lengths=True)\n",
        "\n",
        "LABEL = data.LabelField(dtype = torch.float, batch_first=True)\n",
        "\n",
        "training_data=data.TabularDataset(path = 'quora_data/train.csv',\n",
        "                                  format = 'csv',\n",
        "                                  fields = [\n",
        "                                      (None, None),\n",
        "                                      ('text', TEXT),\n",
        "                                      ('label', LABEL)\n",
        "                                  ],\n",
        "                                  skip_header = True)\n",
        "\n",
        "#print preprocessed text\n",
        "print(vars(training_data.examples[0]))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning: LabelField class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'text': ['How', 'did', 'Quebec', 'nationalists', 'see', 'their', 'province', 'as', 'a', 'nation', 'in', 'the', '1960s?'], 'label': '0'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_PEgFgl28T9"
      },
      "source": [
        "### Split into training and validation datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlKftXpd28T9"
      },
      "source": [
        "train_data, test_data = training_data.split(split_ratio=0.5, random_state = random.seed(SEED))\n",
        "train_data, valid_data = train_data.split(split_ratio=0.4, random_state = random.seed(SEED))\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEUzcYmD28T-"
      },
      "source": [
        "### Prepare input sequence\n",
        "This step takes 3-5 min"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX6htv4p28T-"
      },
      "source": [
        "#Build vocab dictionary\n",
        "TEXT.build_vocab(train_data, min_freq=3, vectors = \"glove.6B.100d\")  \n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXi9Fjos28T_",
        "outputId": "660487da-7b2f-4f11-e346-aff4ff3cfd8d"
      },
      "source": [
        "print(\"Size of TEXT vocabulary: {}\\n\".format(len(TEXT.vocab)))\n",
        "\n",
        "print(\"Size of LABEL vocabulary: {}\\n\".format(len(LABEL.vocab)))\n",
        "\n",
        "print(\"Commonly used words: {}\\n\".format(TEXT.vocab.freqs.most_common(10)))\n",
        "\n",
        "#Word dictionary\n",
        "#TEXT.vocab.stoi"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of TEXT vocabulary: 47144\n",
            "\n",
            "Size of LABEL vocabulary: 2\n",
            "\n",
            "Commonly used words: [('the', 130888), ('What', 83465), ('to', 80575), ('a', 80372), ('in', 72566), ('of', 66277), ('is', 66124), ('I', 61145), ('How', 52158), ('and', 50283)]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSXCdbl228T_"
      },
      "source": [
        "### Prepare training data generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yj7KRbn528T_",
        "outputId": "59c04fcd-a694-4a85-ac76-842d22184029"
      },
      "source": [
        "#check whether cuda is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
        "\n",
        "#set batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "#Load an iterator\n",
        "train_iterator, test_iterator, valid_iterator = data.BucketIterator.splits(\n",
        "    (train_data, test_data, valid_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key = lambda x: len(x.text),\n",
        "    sort_within_batch=True,\n",
        "    device = device)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLvZelI828UA"
      },
      "source": [
        "### LSTM Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnJumaCk28UA"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class classifier(nn.Module):\n",
        "    \n",
        "    #define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                 bidirectional, dropout):\n",
        "        \n",
        "        #Constructor\n",
        "        super().__init__()          \n",
        "        \n",
        "        #embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        #lstm layer\n",
        "        self.lstm = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout,\n",
        "                           batch_first=True)\n",
        "        \n",
        "        #dense layer\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        \n",
        "        #activation function\n",
        "        self.act = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        #text = [batch size,sent_length]\n",
        "        embedded = self.embedding(text)\n",
        "        #embedded = [batch size, sent_len, emb dim]\n",
        "      \n",
        "        #packed sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths,batch_first=True)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
        "        #hidden = [batch size, num layers * num directions,hid dim]\n",
        "        #cell = [batch size, num layers * num directions,hid dim]\n",
        "        \n",
        "        #concat the final forward and backward hidden state\n",
        "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
        "                \n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "        dense_outputs=self.fc(hidden)\n",
        "\n",
        "        #Final activation function\n",
        "        outputs=self.act(dense_outputs)\n",
        "        \n",
        "        return outputs\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_-DQMJl28UB"
      },
      "source": [
        "#### Instantiate a LSTM Classifier model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEJ48Jl028UC"
      },
      "source": [
        "#define hyperparameters\n",
        "size_of_vocab = len(TEXT.vocab)\n",
        "embedding_dim = 100\n",
        "num_hidden_nodes = 32\n",
        "num_output_nodes = 1\n",
        "num_layers = 2\n",
        "bidirection = True\n",
        "dropout = 0.2\n",
        "\n",
        "#instantiate the model\n",
        "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes,num_output_nodes, num_layers, \n",
        "                   bidirectional = True, dropout = dropout)\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HpdVmf928UC"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Z8KI1F_28UC",
        "outputId": "403a56b1-29e6-462e-f1cb-3d8ece3e158c"
      },
      "source": [
        "#architecture\n",
        "print(model)\n",
        "\n",
        "#No. of trainable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier(\n",
            "  (embedding): Embedding(47144, 100)\n",
            "  (lstm): LSTM(100, 32, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
            "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
            "  (act): Sigmoid()\n",
            ")\n",
            "The model has 4,773,857 trainable parameters\n",
            "torch.Size([47144, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00oWzR_L28UD"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "#define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "#define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(preds)\n",
        "    \n",
        "    correct = (rounded_preds == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "#push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92lCtwx028UD",
        "outputId": "bb47dea4-fa7a-4643-fcd0-2ffce06915d6"
      },
      "source": [
        "device"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE1MwxkV28UE"
      },
      "source": [
        "### Model Train function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HWYPhC928UF"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    #initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    #set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        #resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        #retrieve text and no. of words\n",
        "        text, text_lengths = batch.text   \n",
        "        \n",
        "        #convert to 1D tensor\n",
        "        predictions = model(text, text_lengths).squeeze()  \n",
        "        \n",
        "        #compute the loss\n",
        "        loss = criterion(predictions, batch.label)        \n",
        "        \n",
        "        #compute the binary accuracy\n",
        "        acc = binary_accuracy(predictions, batch.label)   \n",
        "        \n",
        "        #backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        #update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        #loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgeaXiLH28UF"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlZpnsZL28UG"
      },
      "source": [
        "### Model Evaluate function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s6gRYx928UG"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    #initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    #deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    #deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            #retrieve text and no. of words\n",
        "            text, text_lengths = batch.text\n",
        "            \n",
        "            #convert to 1d tensor\n",
        "            predictions = model(text, text_lengths).squeeze()\n",
        "            \n",
        "            #compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "            \n",
        "            #keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoTDOtUn28UH"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiGyt1b328UH"
      },
      "source": [
        "### Check model's forward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E20Lgi3728UH",
        "outputId": "bb8a3913-2892-483a-fea5-1be4a8287594"
      },
      "source": [
        "#Check model device type\n",
        "next(model.parameters()).is_cuda, device"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(False, device(type='cpu'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbuHV7P528UH",
        "outputId": "55b776a8-ebb8-41da-e2aa-58857d4becba"
      },
      "source": [
        "for batch in train_iterator:\n",
        "    #retrieve text and no. of words\n",
        "    text, text_lengths = batch.text\n",
        "    print (\"text.shape: \", text.shape)\n",
        "    #convert to 1D tensor\n",
        "    predictions = model(text, text_lengths)\n",
        "    print (\"predictions.shape: \", predictions.shape)\n",
        "    break\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text.shape:  torch.Size([64, 7])\n",
            "predictions.shape:  torch.Size([64, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjQ4qOdg28UI",
        "outputId": "4fd5be73-ee50-4111-f71b-70832a581294"
      },
      "source": [
        "text[0:4]\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   19,  3219,     0,    74,    27,  1217, 14721],\n",
              "        [   16,    12, 30593,  6710,    54,    14,   222],\n",
              "        [    3,    12,    35,    54,   629,  5609,  6331],\n",
              "        [   19,  4848,   757,   182,    14,    28,  2089]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kxIwYz328UI"
      },
      "source": [
        "model_path = 'saved_weights.pt'"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0QBFJC-28UJ"
      },
      "source": [
        "### Train the model\n",
        "\n",
        "This step takes around ~4 min"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjzOQvY-28UJ",
        "outputId": "17e4fe0f-63df-444e-9436-754016ebae9b"
      },
      "source": [
        "N_EPOCHS = 1\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    #train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    #evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "    \n",
        "    ts_string = datetime.now().strftime(\"%m/%d/%Y %H:%M:%S\")\n",
        "\n",
        "    print(f'\\n {ts_string} Epoch: {epoch}')\n",
        "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 03/12/2021 10:24:13 Epoch: 0\n",
            "\t Train Loss: 0.151 | Train Acc: 94.60%\n",
            "\t Val. Loss: 0.129 |  Val. Acc: 95.07%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7EhsX_728UJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV5k5qOD28UK"
      },
      "source": [
        "### Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vq6GuE8LAQkA",
        "outputId": "230058fb-c63d-4193-990a-abf76d2c941b"
      },
      "source": [
        "model.embedding"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(47144, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U503akwY28UK"
      },
      "source": [
        "#load weights\n",
        "model.load_state_dict(torch.load(model_path));\n",
        "model.eval();\n",
        "\n",
        "def prepare_text(sentence):\n",
        "    # Tokenize\n",
        "    tokenized = [tok for tok in tokenizer(sentence)]\n",
        "    # Replace tokens by index from dictionary\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "    length = [len(indexed)]\n",
        "    # Convert to tensors\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(1).T \n",
        "    length = torch.LongTensor(length)\n",
        "    return tensor, length\n",
        "\n",
        "def predict(model, sentence):\n",
        "    tensor, length = prepare_text(sentence)\n",
        "    prediction = model(tensor, length)                  #prediction \n",
        "    return prediction.item()  "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOlyiped28UK",
        "outputId": "39aedea4-8f09-4c6d-a497-17a38d8d3724"
      },
      "source": [
        "sentence = \"What is your favorite person in history?\"\n",
        "tokenized = [tok for tok in tokenizer(sentence)]\n",
        "indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "[len(indexed)]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlYwWYOI28UL"
      },
      "source": [
        "def insincere_or_not(pred):\n",
        "    return 'Insincere Question' if pred > .5 else 'Normal Question'"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2-FRtfZ28UL",
        "outputId": "d3b9f22c-975b-4a7c-935b-357745ca64d9"
      },
      "source": [
        "#sincere question\n",
        "pred = predict(model, \"What is your favorite person in history?\")\n",
        "print (insincere_or_not(pred))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Question\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gz51rH8u28UL",
        "outputId": "60738f31-145b-4a4c-e9c0-eeea3fec131b"
      },
      "source": [
        "#insincere question\n",
        "pred = predict(model, \"Why Indian girls go crazy about marrying Shri. Rahul Gandhiji?\")\n",
        "print (insincere_or_not(pred))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Insincere Question\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNRv_GHz28UM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJHwXTYs-9kB"
      },
      "source": [
        "### Exercise 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0zbdzL-B1Ns"
      },
      "source": [
        "Train the model using the pretrained weights from Glove.  Check the accuracy after 1 epoch and compare."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKslsRk8-8Ny"
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "print(pretrained_embeddings.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiUPda3v-8St"
      },
      "source": [
        "# TODO \n",
        "# Set model embedding's weights to the weights in pretrained_embeddings\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGkn5J0ZBB5a"
      },
      "source": [
        "# TODO \n",
        "# Train the model for 1 epoch and compare loss and accuracy\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1Qs0ZomBB8M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjA23o1oBB-k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn7sS4rd_xIL",
        "outputId": "daf22ee3-ac96-4c18-d9b8-acaaf0804e4b"
      },
      "source": [
        "N_EPOCHS = 1\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "model.embedding = nn.Embedding.from_pretrained(pretrained_embeddings)\n",
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    #train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    #evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "    \n",
        "    ts_string = datetime.now().strftime(\"%m/%d/%Y %H:%M:%S\")\n",
        "\n",
        "    print(f'\\n {ts_string} Epoch: {epoch}')\n",
        "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 03/12/2021 10:50:35 Epoch: 0\n",
            "\t Train Loss: 0.160 | Train Acc: 94.29%\n",
            "\t Val. Loss: 0.148 |  Val. Acc: 94.61%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTLBvuD3-8XE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__aeSc4wDML2"
      },
      "source": [
        "### Exercise 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm_NvjHCDQnp"
      },
      "source": [
        "Find the threshold to predict insincere comments with high precision (>99%)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uy_vXj9Ei-f"
      },
      "source": [
        "def predict (model, iterator):\n",
        "    \n",
        "    #initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    #deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    preds = []\n",
        "    labels = []\n",
        "\n",
        "    #deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            #retrieve text and no. of words\n",
        "            text, text_lengths = batch.text\n",
        "\n",
        "            labels_ = batch.label\n",
        "            \n",
        "            #convert to 1d tensor\n",
        "            preds_ = model(text, text_lengths).squeeze()\n",
        "\n",
        "            preds += preds_.tolist()\n",
        "            labels += labels_.tolist()\n",
        "        \n",
        "    return preds, labels"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izoOVvSS-8ej",
        "outputId": "a4dd8d41-0f65-431b-fac2-7fd7d78cbfca"
      },
      "source": [
        "predprobs, labels = predict(model, test_iterator)\n",
        "\n",
        "preds = [0 if p < .5 else 1 for p in predprob]"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5GI5EsHK8dS"
      },
      "source": [
        ""
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vAVthv3FfnW"
      },
      "source": [
        "d = {'predprob':predprobs, 'pred':preds, 'label':labels}\n",
        "\n",
        "df  = pd.DataFrame(d)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "YtDatvYIFfqP",
        "outputId": "25b37d9e-9c07-4ef0-8371-da9ab2094aff"
      },
      "source": [
        "df[df['label']==1]['predprob'].hist()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fcb4c9fbf90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "PvlQfH2uFfs6",
        "outputId": "485b807d-f10b-4a6b-b824-1850daf54b8e"
      },
      "source": [
        "df[df['label']==0]['predprob'].hist()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fcb48ca3f50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7MxVuCCFfvo"
      },
      "source": [
        "def precision (df):\n",
        "  p = len(df[df['pred'] == 1])\n",
        "  tp = len(df[(df['pred'] == 1) & (df['label'] == 1)])\n",
        "  return tp / p"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxjK3i-qBIGV",
        "outputId": "a8d15ac4-a2c1-44d9-b4e3-1021d07d5d02"
      },
      "source": [
        "precision(df)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6596868398160806"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAS8a9_lM5P8"
      },
      "source": [
        "##TODO\n",
        "\n",
        "Find the optimal threshold to use to achieve >99% precision.\n",
        "\n",
        "- Write a function to calculate precision based on predprobs, labels, threshold\n",
        "- Search for optimal threshold to achieve >99% precision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgqZ5YdFJk6_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2N2RTq2UC_fV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBEEp4xYDE33"
      },
      "source": [
        "### Exercise 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VOYNGtTDJM1"
      },
      "source": [
        "Discuss thresholding practices used in implementing solutions in a business environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN4gE1iFC_lw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmgdLxvbC_n6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hClRCrWC_qE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ7S8foqC_sh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NgLWwezC_vD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybsBKJOBC_xa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRJYJAIi28UM"
      },
      "source": [
        "### Note\n",
        "\n",
        "This notebook used data and code from a blog in https://www.analyticsvidhya.com"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sXDfOLw28UM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}